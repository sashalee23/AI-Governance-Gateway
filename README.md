# Project Title
AI Governance Gateway

A very careful middle-man that sits between a user and an AI-Model and asks questions like:
    "Should I even let the AI answer this?"
    "If it answers, is the answer safe?"
    "Can I explain later why this answer was given?"

Why? 
Because LLMs are untrusted dependencies and AI systems without audit logs should not exist. This is a system designed to track WHY a descision was made by an AI system while also putting guardrails in place to decide IF a decision should be made by an AI.

This is an LLM wrapper API with auditability, policy enforcement and verification.


## License
MIT 

## Contact
*   LinkedIn: [linkedin.com](https://www.linkedin.com/in/sasha-naude/)
*   Email: sasha.naude1@gmail.com

=